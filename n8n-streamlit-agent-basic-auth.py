import streamlit as st
import requests
import uuid

# Constants
WEBHOOK_URL = "https://n8n.srv792087.hstgr.cloud/webhook/e985d15f-b2f6-456d-be15-97e0b1544a40/chat"
BEARER_TOKEN = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJjN2Y1MTU2My00YzdhLTRlZjgtYmIyMC1mNTAxZGI4ZDc3OWUiLCJpc3MiOiJuOG4iLCJhdWQiOiJwdWJsaWMtYXBpIiwiaWF0IjoxNzQ2Mzc1ODQxLCJleHAiOjE3NDg5MDE2MDB9.985Iqo51r--sqd9jrvtbr_lOH5seRUIAN6QYXe73Ty8"

# H√†m ƒë·ªçc n·ªôi dung t·ª´ file vƒÉn b·∫£n
def rfile(name_file):
    #try:
    with open(name_file, "r", encoding="utf-8") as file:
        return file.read()
    #except FileNotFoundError:
    #    return "Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi Tr·ª£ L√Ω AI!"  # N·ªôi dung m·∫∑c ƒë·ªãnh n·∫øu file kh√¥ng t·ªìn t·∫°i

def generate_session_id():
    return str(uuid.uuid4())

def send_message_to_llm(session_id, message):
    headers = {
        "Authorization": f"Bearer {BEARER_TOKEN}",
        "Content-Type": "application/json"
    }
    payload = {
        "sessionId": session_id,
        "chatInput": message
    }
    try:
        response = requests.post(WEBHOOK_URL, json=payload, headers=headers, timeout=10)
        response.raise_for_status()
        return response.json().get("output", "No output received")
    except requests.exceptions.RequestException as e:
        return f"Error: Failed to connect to the LLM - {str(e)}"

def main():
    # Hi·ªÉn th·ªã logo (n·∫øu c√≥)
    try:
        col1, col2, col3 = st.columns([3, 2, 3])
        with col2:
            st.image("logo.png", use_container_width=True)
    except:
        pass
    # Hi·ªÉn th·ªã ti√™u ƒë·ªÅ
    title_content = rfile("00.xinchao.txt")
    print ("title_content",title_content)
    st.markdown(
        f"""<h1 style="text-align: center; font-size: 24px;">{title_content}</h1>""",
        unsafe_allow_html=True
    )

    # Kh·ªüi t·∫°o session state
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "session_id" not in st.session_state:
        st.session_state.session_id = generate_session_id()

    # CSS ƒë·ªÉ cƒÉn ch·ªânh tr·ª£ l√Ω b√™n tr√°i, ng∆∞·ªùi h·ªèi b√™n ph·∫£i, v√† th√™m icon tr·ª£ l√Ω
    st.markdown(
        """
        <style>
            .assistant {
                padding: 10px;
                border-radius: 10px;
                max-width: 75%;
                background: none; /* M√†u trong su·ªët */
                text-align: left;
            }
            .user {
                padding: 10px;
                border-radius: 10px;
                max-width: 75%;
                background: none; /* M√†u trong su·ªët */
                text-align: right;
                margin-left: auto;
            }
            .assistant::before { content: "ü§ñ "; font-weight: bold; }
        </style>
        """,
        unsafe_allow_html=True
    )

    # Hi·ªÉn th·ªã l·ªãch s·ª≠ tin nh·∫Øn
    for message in st.session_state.messages:
        if message["role"] == "assistant":
            st.markdown(f'<div class="assistant">{message["content"]}</div>', unsafe_allow_html=True)
        elif message["role"] == "user":
            st.markdown(f'<div class="user">{message["content"]}</div>', unsafe_allow_html=True)

    # √î nh·∫≠p li·ªáu cho ng∆∞·ªùi d√πng
    if prompt := st.chat_input("Nh·∫≠p n·ªôi dung c·∫ßn trao ƒë·ªïi ·ªü ƒë√¢y nh√©?"):
        # L∆∞u tin nh·∫Øn ng∆∞·ªùi d√πng
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.markdown(f'<div class="user">{prompt}</div>', unsafe_allow_html=True)

        # G·ª≠i y√™u c·∫ßu ƒë·∫øn LLM v√† nh·∫≠n ph·∫£n h·ªìi
        with st.spinner("ƒêang ch·ªù ph·∫£n h·ªìi t·ª´ AI..."):
            llm_response = send_message_to_llm(st.session_state.session_id, prompt)

        # Hi·ªÉn th·ªã v√† l∆∞u ph·∫£n h·ªìi c·ªßa tr·ª£ l√Ω
        st.markdown(f'<div class="assistant">{llm_response}</div>', unsafe_allow_html=True)
        st.session_state.messages.append({"role": "assistant", "content": llm_response})

if __name__ == "__main__":
    main()